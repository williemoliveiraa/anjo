{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import cv2  # type:ignore\n",
    "from requests import post\n",
    "from httpx import get\n",
    "from uuid import getnode as get_mac\n",
    "\n",
    "SERVER_URL_SANITATION = \"http://higienize.senfio.com.br:8080/senfio/HM\"\n",
    "SERVER_URL_FACE = \"http://higienize.senfio.com.br:8080/senfio/leito\"\n",
    "FACES_FOUND_HANDS_SANITATION = {}\n",
    "FACES_FOUND = {}\n",
    "PATH_TO_SAVE_BY_HANDS_SANITATION = \"./hands/\"\n",
    "PATH_TO_SAVE_BY_GET_FACE = \"./get_face/\"\n",
    "\n",
    "def get_datetime():\n",
    "    return datetime.now()\n",
    "\n",
    "def get_timestamp():\n",
    "    return time.time()\n",
    "\n",
    "def get_mac_str():\n",
    "    mac = get_mac()\n",
    "    mac = ':'.join((\"%012X\" % mac)[i:i+2] for i in range(0, 12, 2))\n",
    "    return mac\n",
    "\n",
    "def cv2_to_base64(image) -> str:\n",
    "    return base64.b64encode(image).decode(\"utf8\")\n",
    "\n",
    "def storage_face_by_hands_sanitation(image_face):    \n",
    "    global FACES_FOUND_HANDS_SANITATION\n",
    "    FACES_FOUND_HANDS_SANITATION.update({get_timestamp():image_face})\n",
    "\n",
    "def storage_face_by_get_face(image_face):    \n",
    "    global FACES_FOUND\n",
    "    FACES_FOUND.update({get_timestamp():image_face})\n",
    "\n",
    "def send_image_to_server(action):\n",
    "    global FACES_FOUND_HANDS_SANITATION\n",
    "    global FACES_FOUND\n",
    "    dict_to_send = {}\n",
    "    url_to_send = SERVER_URL_SANITATION\n",
    "    if action == \"sanitation\":\n",
    "        dict_to_send = FACES_FOUND_HANDS_SANITATION\n",
    "    else:\n",
    "        dict_to_send = FACES_FOUND\n",
    "        url_to_send = SERVER_URL_FACE\n",
    "    if not len(dict_to_send) > 0:\n",
    "        return None\n",
    "    for timestamp, image_face in dict_to_send.items():\n",
    "        break\n",
    "    _, encoded_image = cv2.imencode(\".jpg\", image_face)\n",
    "    encoded_image = encoded_image.tobytes()\n",
    "    image_64 = cv2_to_base64(encoded_image)\n",
    "    data = {\"images\":[image_64], \"timestamp\":str(timestamp), \"mac\":str(get_mac_str())}\n",
    "    try:\n",
    "        response = post(\n",
    "            url=url_to_send,\n",
    "            headers={\"Content-type\": \"application/json\"},\n",
    "            data=json.dumps(data),\n",
    "            timeout=10,\n",
    "        ).json()\n",
    "        if response.ok:\n",
    "            print(f\"Imagem enviada! Status code: {response.status_code}\")\n",
    "        else:\n",
    "            print(f\"Imagem nÃ£o enviada! Status code: {response.status_code}\")\n",
    "    except:\n",
    "        pass\n",
    "    del dict_to_send[timestamp]\n",
    "    if action == \"sanitation\":\n",
    "        FACES_FOUND_HANDS_SANITATION = dict_to_send\n",
    "    else:\n",
    "        FACES_FOUND = dict_to_send\n",
    "\n",
    "def send_request_to_led(function):\n",
    "    server = \"http://localhost:8080/\" + str(function)\n",
    "    try:\n",
    "        get(server, timeout = 0.01)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def save_hands_sanitation_imagem_in_local():\n",
    "    global FACES_FOUND_HANDS_SANITATION\n",
    "    if not len(FACES_FOUND_HANDS_SANITATION) > 0:\n",
    "        return None     \n",
    "    for timestamp, image_to_save in FACES_FOUND_HANDS_SANITATION.items():\n",
    "        break\n",
    "    cv2.imwrite(f\"{PATH_TO_SAVE_BY_HANDS_SANITATION}{str(timestamp)}.jpg\", image_to_save)\n",
    "    print(\"Salvando imagem em: \"+f\"{PATH_TO_SAVE_BY_HANDS_SANITATION}{str(timestamp)}.jpg\")\n",
    "    del FACES_FOUND_HANDS_SANITATION[timestamp]\n",
    "\n",
    "def save_face_imagem_in_local():\n",
    "    global FACES_FOUND\n",
    "    #print(\"Salvando face no local...\")\n",
    "    if not len(FACES_FOUND) > 0:\n",
    "        return None\n",
    "    for timestamp, image_to_save in FACES_FOUND.items():\n",
    "        break\n",
    "    cv2.imwrite(f\"{PATH_TO_SAVE_BY_GET_FACE}{str(timestamp)}.jpg\", image_to_save)\n",
    "    print(\"Salvando imagem em: \"+f\"{PATH_TO_SAVE_BY_GET_FACE}{str(timestamp)}.jpg\")\n",
    "    del FACES_FOUND[timestamp]\n",
    "\n",
    "import numpy as np  # type:ignore\n",
    "import PIL.Image\n",
    "import torch  # type:ignore\n",
    "import torch2trt  # type:ignore\n",
    "import torchvision.transforms as transforms  # type:ignore\n",
    "import trt_pose.coco  # type:ignore\n",
    "import trt_pose.models  # type:ignore\n",
    "from jetcam.csi_camera import CSICamera  # type:ignore\n",
    "from torch2trt import TRTModule  # type:ignore\n",
    "from trt_pose.draw_objects import DrawObjects  # type:ignore\n",
    "from trt_pose.parse_objects import ParseObjects  # type:ignore\n",
    "\n",
    "with open(\"human_pose.json\", \"r\") as f:\n",
    "    human_pose = json.load(f)\n",
    "\n",
    "TOPOLOGY = trt_pose.coco.coco_category_to_topology(human_pose)\n",
    "NUM_PARTS = len(human_pose[\"keypoints\"])\n",
    "NUM_LINKS = len(human_pose[\"skeleton\"])\n",
    "MODEL = trt_pose.models.resnet18_baseline_att(NUM_PARTS, 2 * NUM_LINKS).cuda().eval()\n",
    "MODEL_WEIGHTS = \"resnet18_baseline_att_224x224_A_epoch_249.pth\"\n",
    "MODEL.load_state_dict(torch.load(MODEL_WEIGHTS))\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "DATA = torch.zeros((1, 3, HEIGHT, WIDTH)).cuda()\n",
    "\n",
    "TRT_MODEL = torch2trt.torch2trt(\n",
    "    MODEL, [DATA], fp16_mode=True, max_workspace_size=1 << 25\n",
    ")\n",
    "\n",
    "OPTIMIZED_MODEL = \"resnet18_baseline_att_224x224_A_epoch_249_trt.pth\"\n",
    "torch.save(TRT_MODEL.state_dict(), OPTIMIZED_MODEL)\n",
    "\n",
    "TRT_MODEL = TRTModule()\n",
    "TRT_MODEL.load_state_dict(torch.load(OPTIMIZED_MODEL))\n",
    "MEAN = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "STD = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "CAMERA = CSICamera(\n",
    "    width=WIDTH, height=HEIGHT, capture_width=3264, capture_height=2464, capture_fps=21\n",
    ")\n",
    "CAMERA.running = True\n",
    "WRIST_IN_BBOX = []\n",
    "ACCEPTABLE_DISTANCE = []\n",
    "VERIFIED_WRIST = []\n",
    "\n",
    "PARSE_OBJECTS = ParseObjects(TOPOLOGY)\n",
    "DRAW_OBJECTS = DrawObjects(TOPOLOGY)\n",
    "\n",
    "def get_fps():\n",
    "    t0 = time.time()\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    for _ in range(50):\n",
    "        _ = TRT_MODEL(DATA)\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "    fps = (50.0 / (t1 - t0))\n",
    "    print(f\"FPS: {fps}\")\n",
    "    return int(fps)\n",
    "\n",
    "APPLICATION_FPS = get_fps()\n",
    "APPLICATION_FPS = get_fps()\n",
    "\n",
    "def preprocess(image):\n",
    "    global DEVICE\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(DEVICE)\n",
    "    image.sub_(MEAN[:, None, None]).div_(STD[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def seek_peaks(topology, image, persons, normalized_peaks):\n",
    "    color = (0, 255, 0)\n",
    "    normalized_peaks = normalized_peaks[0]\n",
    "    persons = persons[0]\n",
    "    left_eye = 1\n",
    "    right_eye = 2\n",
    "    left_wrist = 9\n",
    "    right_wrist = 10\n",
    "    left_shoulder = 5\n",
    "    right_shoulder = 6\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    amount_peaks = 0\n",
    "    wrist_coordinates = [0, 0, 0, 0]\n",
    "    face_coordinates = [\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "    ]  # [left_shoulder, left_eye, right_eye, right_shoulder]\n",
    "    person_number = 0\n",
    "    person = persons[person_number]\n",
    "    K = topology.shape[0]\n",
    "    for landmark in range(person.shape[0]):\n",
    "        peak_number = int(person[landmark])\n",
    "        if peak_number < 0:\n",
    "            continue\n",
    "        else:\n",
    "            amount_peaks += 1\n",
    "        peak = normalized_peaks[landmark][peak_number]\n",
    "        x = round(float(peak[1]) * width)\n",
    "        y = round(float(peak[0]) * height)\n",
    "        cv2.circle(image, (x, y), 3, color, 2)\n",
    "        if landmark == left_shoulder:\n",
    "            face_coordinates[0] = (x, y)\n",
    "        if landmark == left_eye:\n",
    "            face_coordinates[1] = (x, y)\n",
    "        if landmark == right_eye:\n",
    "            face_coordinates[2] = (x, y)\n",
    "        if landmark == right_shoulder:\n",
    "            face_coordinates[3] = (x, y)\n",
    "        if landmark == left_wrist:\n",
    "            wrist_coordinates[0] = x\n",
    "            wrist_coordinates[1] = y\n",
    "        if landmark == right_wrist:\n",
    "            wrist_coordinates[2] = x\n",
    "            wrist_coordinates[3] = y\n",
    "    \n",
    "    for k in range(K):\n",
    "        c_a = topology[k][2]\n",
    "        c_b = topology[k][3]\n",
    "        if person[c_a] >= 0 and person[c_b] >= 0:\n",
    "            peak0 = normalized_peaks[c_a][person[c_a]]\n",
    "            peak1 = normalized_peaks[c_b][person[c_b]]\n",
    "            x0 = round(float(peak0[1]) * width)\n",
    "            y0 = round(float(peak0[0]) * height)\n",
    "            x1 = round(float(peak1[1]) * width)\n",
    "            y1 = round(float(peak1[0]) * height)\n",
    "            cv2.line(image, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "    return wrist_coordinates, face_coordinates, amount_peaks\n",
    "\n",
    "# BBOX: [A B\n",
    "#       D C]\n",
    "def join_bbox(bbox_max, bbox_min):\n",
    "    add = 5\n",
    "    bbox_max_points = bbox_max.tolist()\n",
    "    bbox_min_points = bbox_min.tolist()\n",
    "    contour_points = bbox_max_points + bbox_min_points\n",
    "    x_points: list[int] = [point[0] for point in contour_points]\n",
    "    y_points: list[int] = [point[1] for point in contour_points]\n",
    "\n",
    "    min_x = min(x_points)\n",
    "    min_y = min(y_points)\n",
    "    max_x = max(x_points)\n",
    "    max_y = max(y_points)\n",
    "\n",
    "    min_x -= add * 3\n",
    "    min_y -= add * 3\n",
    "    max_x += add * 3\n",
    "    max_y += add * 3\n",
    "\n",
    "    bbox = np.int0(\n",
    "        [[min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y]]  # type:ignore\n",
    "    )\n",
    "    return bbox\n",
    "\n",
    "def identify_lines(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 150, 150])\n",
    "    upper = np.array([10, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    red_contours = cv2.findContours(\n",
    "        mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )[-2]\n",
    "    try:\n",
    "        ordered_red_contours = sorted(red_contours, reverse=True, key=cv2.contourArea)\n",
    "        max_red_box = cv2.boxPoints(cv2.minAreaRect(ordered_red_contours[0]))\n",
    "        min_red_box = cv2.boxPoints(cv2.minAreaRect(ordered_red_contours[1]))\n",
    "        max_red_box = np.int0(max_red_box)\n",
    "        min_red_box = np.int0(min_red_box)\n",
    "        red_bbox = join_bbox(max_red_box, min_red_box)\n",
    "        cv2.drawContours(image, [red_bbox], 0, (255, 0, 255), 2)\n",
    "    except:\n",
    "        red_bbox = np.int0([[0, 0], [0, 0], [0, 0], [0, 0]])\n",
    "    return red_bbox\n",
    "\n",
    "def verify_wrist_in_bbox(wrist, bbox):\n",
    "    return wrist[0] in range(bbox[0][0] + 1, bbox[1][0]) and wrist[1] in range(\n",
    "        bbox[0][1] + 1, bbox[2][1]\n",
    "    )\n",
    "\n",
    "def verify_wrists_in_bbox(image, wrist_coordinates):\n",
    "    bbox = identify_lines(image)\n",
    "    left_wrist = np.int0([wrist_coordinates[0], wrist_coordinates[1]])  # type:ignore\n",
    "    right_wrist = np.int0([wrist_coordinates[2], wrist_coordinates[3]])  # type:ignore\n",
    "    if verify_wrist_in_bbox(left_wrist, bbox) or verify_wrist_in_bbox(\n",
    "        right_wrist, bbox\n",
    "    ):\n",
    "        WRIST_IN_BBOX.append(True)\n",
    "        if WRIST_IN_BBOX.count(True) == 3:\n",
    "            print(\"pulso por 3x seguidas\")\n",
    "            VERIFIED_WRIST.append(True)\n",
    "            del WRIST_IN_BBOX[:]\n",
    "    else:\n",
    "        del VERIFIED_WRIST[:]\n",
    "        del WRIST_IN_BBOX[:]\n",
    "\n",
    "def verify_hands_sanitation(acceptable_distance, image_face, image):\n",
    "    if acceptable_distance.count(True) >= int(len(acceptable_distance) * 0.8):\n",
    "        print(\n",
    "            str(acceptable_distance.count(True))\n",
    "            + \" >= \"\n",
    "            + str(int(len(acceptable_distance) * 0.8))\n",
    "        )\n",
    "        print(\"HigienizaÃ§Ã£o\")\n",
    "        storage_face_by_hands_sanitation(image_face)\n",
    "        cv2.putText(image, \"H\", (112 , 112), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        send_request_to_led(\"hands\")\n",
    "    else:\n",
    "        print(\n",
    "            str(acceptable_distance.count(True))\n",
    "            + \" < \"\n",
    "            + str(int(len(acceptable_distance) * 0.8))\n",
    "        )\n",
    "        print(\"NÃO higienizaÃ§Ã£o\")\n",
    "    del acceptable_distance[:]\n",
    "\n",
    "def verify_wrist_union(wrist_coordinates, image_face, image):\n",
    "    diff_axis_ok = 30\n",
    "    left_wrist = np.int0([wrist_coordinates[0], wrist_coordinates[1]])  # type:ignore\n",
    "    right_wrist = np.int0([wrist_coordinates[2], wrist_coordinates[3]])  # type:ignore\n",
    "\n",
    "    x_distance = abs(right_wrist[0] - left_wrist[0])  # type:ignore\n",
    "    y_distance = abs(right_wrist[1] - left_wrist[1])  # type:ignore\n",
    "    if (\n",
    "        not 0 in (x_distance, y_distance)\n",
    "        and x_distance <= diff_axis_ok\n",
    "        and y_distance <= diff_axis_ok\n",
    "    ):\n",
    "        ACCEPTABLE_DISTANCE.append(True)\n",
    "    else:\n",
    "        ACCEPTABLE_DISTANCE.append(False)\n",
    "\n",
    "    if len(ACCEPTABLE_DISTANCE) >= 5 * APPLICATION_FPS:\n",
    "        verify_hands_sanitation(ACCEPTABLE_DISTANCE, image_face, image)\n",
    "        del VERIFIED_WRIST[:]\n",
    "\n",
    "def get_face(image, face_coordinates):\n",
    "    required_size = (160, 160)\n",
    "    if face_coordinates[1] != (0, 0) != face_coordinates[2]:\n",
    "        start_x = min(face_coordinates[0][0], face_coordinates[3][0])\n",
    "        end_x = max(face_coordinates[0][0], face_coordinates[3][0])\n",
    "\n",
    "        start_y = (min(face_coordinates[1][1], face_coordinates[2][1])) - 30\n",
    "        end_y = max(face_coordinates[0][1], face_coordinates[3][1])\n",
    "        image_face = image[start_y:end_y, start_x:end_x]\n",
    "        try:\n",
    "            image_face = cv2.resize(\n",
    "                image_face, required_size, interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "            storage_face_by_get_face(image_face)\n",
    "            send_request_to_led(\"bed_entry\")\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        image_face = image[0, 0]\n",
    "    return image_face\n",
    "\n",
    "def verify_people_on_local(amount_peaks, image):\n",
    "    posit = 45\n",
    "    amount_peaks_necessary = 3\n",
    "    if amount_peaks >= amount_peaks_necessary:\n",
    "        #print(\"HÃ¡ pessoa no local\")\n",
    "        cv2.putText(image, \"P\", (posit , posit), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        send_request_to_led(\"person\")\n",
    "    else:\n",
    "        #print(\"NÃ£o hÃ¡ pessoa no local\")\n",
    "        cv2.putText(image, \"N\", (posit, posit), cv2.FONT_HERSHEY_SIMPLEX, 2, (28, 184, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "image_w = ipywidgets.Image(format='jpeg')\n",
    "image_f = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "def execute(change):\n",
    "    wrist_coordinates = [0, 0, 0, 0]  # x_left, y_left, x_right, y_right\n",
    "    face_coordinates = [\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "        (0, 0),\n",
    "    ]  # Ombro esquerdo, olho esquerdo, olho direito, ombro direito\n",
    "    amount_peaks = 0\n",
    "    image = change[\"new\"]\n",
    "    image_copy = image.copy()\n",
    "    data = preprocess(image)\n",
    "    cmap, paf = TRT_MODEL(data)\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "    _, persons, peaks = PARSE_OBJECTS(cmap, paf)\n",
    "    wrist_coordinates, face_coordinates, amount_peaks = seek_peaks(\n",
    "        TOPOLOGY, image, persons, peaks\n",
    "    )\n",
    "    image_face = get_face(image_copy, face_coordinates)\n",
    "    if VERIFIED_WRIST.count(True) >= 1:\n",
    "        verify_wrist_union(wrist_coordinates, image_face, image)\n",
    "    else:\n",
    "        verify_wrists_in_bbox(image, wrist_coordinates)\n",
    "    verify_people_on_local(amount_peaks, image)\n",
    "    try:\n",
    "        image_f.value = bgr8_to_jpeg(image_face)\n",
    "    except:\n",
    "        pass\n",
    "    image = cv2.resize(image, (600,600), interpolation=cv2.INTER_AREA)\n",
    "    image_w.value = bgr8_to_jpeg(image)\n",
    "\n",
    "print(\"-\" * 5 + \" Iniciando App SENFIO - Jetson \" + \"-\" * 5)\n",
    "send_request_to_led(\"init\")\n",
    "execute({\"new\": CAMERA.value})\n",
    "CAMERA.observe(execute, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7738494cf4ac4d6b86bc56b60312ad04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    send_image_to_server(\"face\")\n",
    "    send_image_to_server(\"sanitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA.unobserve_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bedfc9a1a57238c584ba5d27e7f70cd0b97161096ab2945104d5074edba1316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
